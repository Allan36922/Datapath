{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMOe12yWlm8K"
      },
      "source": [
        "# Ejercicios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN4kJcUUltXO"
      },
      "source": [
        "Los datos adjuntos a esta lección forman parte de la base de datos [NeurIPS 2020] Data Science for COVID-19 (DS4C) disponible en Kaggle. Estos datos hacen referencia a los casos de contagio de covid-19 en Corea del Sur.\n",
        "\n",
        "\n",
        "\n",
        "El archivo csv Case contiene los casos reportados y el archivo csv PatientInfo contiene la información de los pacientes.\n",
        "\n",
        "\n",
        "\n",
        "1. A partir del archivo csv Case, determine las tres ciudades con más casos confirmados de la enfermedad. La salida debe contener tres columnas: provincia, ciudad y casos confirmados. El resultado debe contener exactamente los tres nombre de ciudades con más casos confirmados ya que no se admiten otros valores.\n",
        "\n",
        "2. Cree un dataframe a partir del archivo csv PatientInfo. Asegúrese de que su dataframe no contenga pacientes duplicados.\n",
        "\n",
        "a. ¿Cuántos pacientes tienen informado por quién se contagiaron(columna infected_by)? Obtenga solo los pacientes que tengan informado por quién se contagiaron.\n",
        "b. A partir de la salida del inciso anterior obtenga solo los pacientes femeninos. La salida no debe contener las columnas released_date y deceased_date.\n",
        "c. Establezca el número de particiones del dataframe resultante del inciso anterior en dos. Escriba el dataframe resultante en un archivo parquet. La salida debe estar particionada por la provincia y el modo de escritura debe ser overwrite.\n",
        "\n",
        "Recursos de esta clase\n",
        "data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5UHg_pMnUt_"
      },
      "outputs": [],
      "source": [
        "# Importar librerías\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.3-bin-hadoop3.2\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Crea una sesión de Spark\n",
        "spark = SparkSession.builder.appName(\"EjercicioDataFrames\").getOrCreate()\n",
        "\n",
        "# 1. Determinar las tres ciudades con más casos confirmados\n",
        "cases_df = spark.read.csv(\"Case.csv\", header=True, inferSchema=True)\n",
        "top_cities = cases_df.groupBy(\"province\", \"city\").sum(\"confirmed\").orderBy(\"sum(confirmed)\", ascending=False).limit(3)\n",
        "\n",
        "# Muestra el resultado\n",
        "top_cities.show()\n",
        "\n",
        "# 2. Crear un DataFrame a partir de PatientInfo.csv\n",
        "patient_info_df = spark.read.csv(\"PatientInfo.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# a. Filtrar pacientes con información de contagio\n",
        "infected_patients = patient_info_df.filter(patient_info_df.infected_by.isNotNull())\n",
        "\n",
        "# Muestra el resultado\n",
        "infected_patients.show()\n",
        "\n",
        "# b. Filtrar pacientes femeninos y seleccionar columnas\n",
        "female_infected = infected_patients.filter(infected_patients.sex == \"female\").select(\n",
        "    \"patient_id\", \"sex\", \"age\", \"country\", \"province\", \"city\", \"infection_case\", \"infected_by\", \"contact_number\", \"symptom_onset_date\", \"confirmed_date\", \"state\"\n",
        ")\n",
        "\n",
        "# Muestra el resultado\n",
        "female_infected.show()\n",
        "\n",
        "# c. Establecer número de particiones y escribir en archivo Parquet\n",
        "female_infected.coalesce(2).write.mode(\"overwrite\").partitionBy(\"province\").parquet(\"data_output/female_infected.parquet\")\n",
        "\n",
        "# Detén la sesión de Spark\n",
        "spark.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
